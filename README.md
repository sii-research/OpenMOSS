# OpenMOSS
[OpenMOSS](https://github.com/OpenMOSS) presents a collection of our research on LLMs, supported by SII, Fudan and Mosi.

# Projects

## MOSS-Audio

### MOSS: Text to Spoken Dialogue Generation
**Release Date**: June 2025

#### üîó Resources
- **ü§ó HuggingFace**: [MOSS-TTSD Models](https://huggingface.co/fnlp/MOSS-TTSD-v0.5)
- **üíª GitHub**: [Source Code & Implementation](https://github.com/OpenMOSS/MOSS-TTSD)

## MOSS-Video
Coming soon!

## MOSS-Robot
Coming soon!

## MOSS-Interp

### Language-Model-SAEs
`Language-Model-SAEs` is a comprehensive, **fully-distributed** framework designed for **training, analyzing and visualizing Sparse Autoencoders (SAEs)**, empowering scalable and systematic **Mechanistic Interpretability** research.

#### üîó Resources
- ü§ó HuggingFace: [Llama Scope](https://huggingface.co/fnlp/Llama-Scope)
- üåê Neuronpedia: [Llama Scope Visualization](https://www.neuronpedia.org/llama-scope)
- üíª GitHub: [Language-Model-SAEs](https://github.com/OpenMOSS/Language-Model-SAEs)

# Research

## Embodied-AI
The Embodied AI Team empowers large models to execute real-world tasks, aiming to automate tedious chores and unlock superhuman intelligence through environmental interaction. We believe true AI emerges from engaging with the physical world.

- **VLABench** [arXiv](https://arxiv.org/abs/2412.18194) [Github](https://github.com/OpenMOSS/VLABench) ICCV 2025
  - The first robot manipulation benchmark designed to evalute the multi-dimensional ability of general purpose Vision-Language-Action Models.
- **Dual Preference Optimization for Embodied Task Planning** [arXiv](https://arxiv.org/abs/2503.10480) [Github](https://github.com/sinwang20/D2PO) ACL 2025
  - A unified learning framework that empowers embodied agents with stronger world modeling and embodied planning ability via dual preference optimization.
- **World-Aware-Planning** [arXiv](https://arxiv.org/pdf/2506.21230) [Github](https://github.com/sii-research/World-Aware-Planning)
  - An innovative world-aware narrative enhancement approach, bridging the gap between high-level task instructions and nuanced details of real-world environment.
- **Embodied-Planner-R1** [arXiv](https://arxiv.org/abs/2506.23127v1) [Github](https://github.com/OpenMOSS/Embodied-Planner-R1)
  - A reinforcement learning framework that enables LLMs to acquire embodied planning capabilities through autonomous exploration with sparse rewards, achieving breakthrough performance in planning tasks that require environmental interaction.

## NewArch
SII-OpenMOSS New Architecture Team explores new architectures and paradigms of LLMs, from the perspective of improving the long-context capability and efficiency of LLMs

- **ReAttention** [arXiv](https://arxiv.org/abs/2407.15176) [Github](https://github.com/OpenMOSS/ReAttention) ICLR 2025
  - A training-free approach that enables LLM to support an infinite context in length extrapolation with finite attention scope.
- **FouierAttention** [arXiv](https://arxiv.org/abs/2506.11886)
  - A training-free framework that exploits the heterogeneous roles of transformer head dimensions.
- **LongLLaDA** [arXiv](https://arxiv.org/abs/2506.14429) [Github](https://github.com/OpenMOSS/LongLLaDA)
  - The first systematic investigation comparing the long-context performance of diffusion LLMs and traditional auto-regressive LLMs.
- **Thus Spake Long-Context LLM** [arXiv](https://arxiv.org/abs/2502.17129) [Github](https://github.com/OpenMOSS/Thus-Spake-Long-Context-LLM)
  - A global picture of the lifecycle of long-context LLMs from four perspectives: architecture, infrastructure, training, and evaluation.
